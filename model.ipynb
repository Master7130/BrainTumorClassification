{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "9c987726e703d696800719aea8c356f9bcb8871f4f57a3e67e8da45e6f7618fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\Bhavesh\\Python\\python_work\\BrainTumorClassification\\Data\\Training\"\n",
    "\n",
    "batch_size = 10\n",
    "img_height = 512\n",
    "img_width = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_path,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",\n",
    "  seed=0,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=0,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "model.fit(\n",
    "  train_data,\n",
    "  validation_data=val_data,\n",
    "  epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"C:\\Bhavesh\\Python\\python_work\\BrainTumorClassification\\Data\\Testing\"\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_path,\n",
    "  validation_split=0.5,\n",
    "  subset=\"training\",\n",
    "  seed=1,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "eval = model.evaluate(test_data)\n",
    "print(\"test loss, test acc:\", eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "model2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.Dropout(.1),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "\n",
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "Callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]\n",
    "\n",
    "model2.fit(\n",
    "  train_data,\n",
    "  validation_data=val_data,\n",
    "  epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/content/drive/MyDrive/Data/Data/Testing\"\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_path,\n",
    "  validation_split=0.01,\n",
    "  subset=\"training\",\n",
    "  seed=1,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "eval = model2.evaluate(test_data)\n",
    "print(\"test loss, test acc:\", eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform', name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_dense_nodes = Integer(low=5, high=512, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu'], name='activation')\n",
    "\n",
    "dimensions = [dim_learning_rate, dim_num_dense_layers, dim_num_dense_nodes, dim_activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = [5.8e-04, 1, 269, 'relu']\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
    "  model = tf.keras.Sequential()\n",
    "\n",
    "  model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255))\n",
    "\n",
    "  model.add(tf.keras.layers.Conv2D(32, 3, activation=activation))\n",
    "  model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "  model.add(tf.keras.layers.Conv2D(32, 3, activation=activation))\n",
    "  model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "  model.add(tf.keras.layers.Conv2D(32, 3, activation=activation))\n",
    "  model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "  for i in range(num_dense_layers):\n",
    "    name = f'dense_layer_{i + 1}'\n",
    "    model.add(tf.keras.layers.Dense(num_dense_nodes, activation=activation, name=name))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(num_classes))\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print()\n",
    "\n",
    "    model = create_model(learning_rate=learning_rate, num_dense_layers=num_dense_layers, num_dense_nodes=num_dense_nodes, activation=activation)\n",
    "\n",
    "    history = model.fit(train_data, validation_data=val_data, epochs=5, batch_size=128)\n",
    "\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    global best_accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "    \n",
    "    del model\n",
    "\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness(default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=40,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = search_result.x\n",
    "print(f\"Best hyper-parameters: {best}\")\n",
    "\n",
    "best_acc = round(abs(search_result.fun), 2)\n",
    "print(f\"Best accuracy: {best_acc}\")\n",
    "\n",
    "\n",
    "'''\n",
    "Best:\n",
    "    learning rate: 5.8e-04\n",
    "    num_dense_layers: 1\n",
    "    num_dense_nodes: 269\n",
    "    activation: relu\n",
    "    epochs: 5\n",
    "'''"
   ]
  }
 ]
}